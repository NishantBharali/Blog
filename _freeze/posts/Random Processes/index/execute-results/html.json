{
  "hash": "943b25909195e2c469f9a48606df3995",
  "result": {
    "markdown": "---\ntitle: Probability Theory and Random Processes\ndescription: \"Gaining insights on weather data with Data Science and Machine Learning\"\ndate: 11-24-2023\ncategories: [Machine_Learning]\nimage: weatherGif.gif\ntoc-location: right\n---\n\n## Gaining insights on weather data with Data Science and Machine Learning\n\nIn this blog post I will discuss a few examples of [probability](https://en.wikipedia.org/wiki/Probability#:~:text=Probability%20is%20the%20branch%20of,event%20and%201%20indicates%20certainty.) in [machine learning](https://en.wikipedia.org/wiki/Machine_learning#:~:text=Machine%20learning%20(ML)%20is%20a%20field%20of%20study%20in%20artificial%20intelligence%20concerned%20with%20the%20development%20and%20study%20of%20statistical%20algorithms%20that%20can%20effectively%20generalize%20and%20thus%20perform%20tasks%20without%20explicit%20instructions.). If you are new to probability, I recommend one of great textbooks that cover the topic and are available for free online, such as [Think Bayes](https://allendowney.github.io/ThinkBayes2) by [Allen Downey](https://www.allendowney.com) and [Bayes Rules!](https://www.bayesrulesbook.com) by [Alicia A. Johnson](https://ajohns24.github.io), Miles Q. Ott, and [Mine Dogucu](https://www.minedogucu.com).\n\n[Classification](https://en.wikipedia.org/wiki/Statistical_classification) [algorithms](https://en.wikipedia.org/wiki/Algorithm) algorithms can estimate $n \\times k$ class membership probabilities for each dataset, where n is the number of data points in the dataset and k is the number of classes in the [training dataset](https://en.wikipedia.org/wiki/Training,_validation,_and_test_data_sets#:~:text=training%20data%20set%2C%5B3%5D%20which%20is%20a%20set%20of%20examples%20used%20to%20fit%20the%20parameters%20(e.g.%20weights%20of%20connections%20between%20neurons%20in%20artificial%20neural%20networks)%20of%20the%20model.). Similarly, the [Gaussian Mixtures](https://scikit-learn.org/stable/modules/mixture.html) [clustering](https://scikit-learn.org/stable/modules/clustering.html) algorithm can generate $n \\times k$ cluster label probabilities.\n\nBesides  a data point and the Gaussian Mixtures models can estimate cluster membership probability. point , especially [Logistic Regression](https://en.wikipedia.org/wiki/Logistic_regression) and [Naive Bayes](https://en.wikipedia.org/wiki/Naive_Bayes_classifier). Every classification algorithm can estimate probabilities of belonging to each class.\n\n$\\Huge P(A\\vert B)={\\frac {P(B\\vert A)P(A)}{P(B)}}$\n\n\n\n## Understanding Weather Forecasting with the help of Probability theory and Random Processes\n\n**Introduction**\n\nMachine learning plays a pivotal role in understanding and predicting various natural phenomena, and weather forecasting is no exception. To harness the power of machine learning for weather data analysis, it is essential to have a solid foundation in random processes and probability theory. These fundamental concepts are the building blocks that enable us to model the inherent uncertainty and variability present in weather data.\n\nWeather data, such as temperature, humidity, wind speed, and precipitation, exhibit random behavior due to the complex interplay of atmospheric processes. Random processes are mathematical models used to describe the evolution of these variables over time. These processes capture the idea that weather conditions are not deterministic but rather stochastic, influenced by a multitude of factors, including geographical location, time of year, and local phenomena.\n\nProbability theory, on the other hand, provides the framework to quantify and reason about uncertainty in weather data. It allows us to assign probabilities to different weather outcomes and make informed predictions based on observed data. For example, we can calculate the probability of rain on a given day or estimate the likelihood of extreme weather events, such as hurricanes or heatwaves, occurring in a specific region.\n\nMachine learning techniques, such as regression, classification, and time series analysis, heavily rely on probabilistic and random process models to extract meaningful insights from weather data. By incorporating these techniques, we can build predictive models that not only provide accurate weather forecasts but also account for uncertainty, enabling better decision-making in various applications like agriculture, transportation, and disaster management.\n\nIn this context, the weather dataset you are using serves as a valuable source of information for exploring and applying these concepts. By understanding random processes and probability theory, you can leverage machine learning to unlock the potential hidden within weather data, improving the accuracy and reliability of weather forecasts and facilitating data-driven decision-making in various sectors that rely on weather information.\n\n**Data Loading and Basic Visualization**\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n# Importing libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom scipy.stats import norm\nfrom scipy.stats import expon\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\n# Load the dataset\nweather_df = pd.read_csv('weather_data.csv')\nweather_df['Date'] = pd.to_datetime(weather_df['Date'])\n```\n:::\n\n\n**Exploratory Data Analysis**\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\n#Exploratory Data Analysis\n#Histograms and KDE (Kernel Density Estimation) plots for Temperature and Humidity.\nsns.histplot(weather_df['Temperature'], kde=True, color='blue', label='Temperature')\nsns.histplot(weather_df['Humidity'], kde=True, color='green', label='Humidity', alpha=0.5)\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-3-output-1.png){width=593 height=429}\n:::\n:::\n\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\n# Pair Plot to visualize all variables together.\nsns.pairplot(weather_df, hue='Weather_Condition')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-4-output-1.png){width=618 height=476}\n:::\n:::\n\n\n**Probability Distributions**\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\n#Normal Distribution Fit for Temperature.\nsns.histplot(weather_df['Temperature'], kde=False, color='blue', label='Temperature')\n\n# Fitting a normal distribution and plotting it\nmean, std = norm.fit(weather_df['Temperature'])\nxmin, xmax = plt.xlim()\nx = np.linspace(xmin, xmax, 100)\np = norm.pdf(x, mean, std)\nplt.plot(x, p * max(weather_df['Temperature'].value_counts()), 'k', linewidth=2)\n\ntitle = \"Fit results: mean = %.2f,  std = %.2f\" % (mean, std)\nplt.title(title)\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-5-output-1.png){width=593 height=449}\n:::\n:::\n\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\n#Exponential Distribution Fit for Humidity.\nfrom scipy.stats import expon\n\n# Plotting histogram\nsns.histplot(weather_df['Humidity'], kde=False, color='green', label='Humidity')\n\n# Fitting an exponential distribution and plotting it\nparams = expon.fit(weather_df['Humidity'])\nxmin, xmax = plt.xlim()\nx = np.linspace(xmin, xmax, 100)\np = expon.pdf(x, *params)\nplt.plot(x, p * max(weather_df['Humidity'].value_counts()), 'k', linewidth=2)\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-6-output-1.png){width=593 height=429}\n:::\n:::\n\n\n**Time Series Analysis**\n\nTemperature Trend over Time.\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\n#Checking the temperature trned against time\nweather_df.set_index('Date')['Temperature'].plot()\nplt.title(\"Temperature Trend Over Time\")\nplt.ylabel(\"Temperature\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-7-output-1.png){width=585 height=449}\n:::\n:::\n\n\n**Probability Theory in Action**\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\n#Conditional Probability: Probability of High Humidity given Rainy Weather.\nhigh_humidity = weather_df['Humidity'] > 80\nrainy_days = weather_df['Weather_Condition'] == 'Rainy'\nprob_high_humidity_given_rain = np.mean(high_humidity[rainy_days])\nprint(f\"Probability of High Humidity given Rainy Weather: {prob_high_humidity_given_rain}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nProbability of High Humidity given Rainy Weather: 0.27586206896551724\n```\n:::\n:::\n\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\n#Joint Distribution: Temperature and Humidity.\nsns.jointplot(data=weather_df, x='Temperature', y='Humidity', kind='kde', color='red')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-9-output-1.png){width=570 height=566}\n:::\n:::\n\n\n**Correlation Analysis**\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\n#Correlation Heatmap\n# Selecting only numerical columns for correlation analysis\nnumerical_weather_df = weather_df.select_dtypes(include=[np.number])\n\n# Plotting the correlation heatmap\nsns.heatmap(numerical_weather_df.corr(), annot=True, cmap='coolwarm')\nplt.title(\"Correlation Heatmap\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-10-output-1.png){width=533 height=431}\n:::\n:::\n\n\n**Linear Regression for Temperature Prediction**\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\n#Model Training and Evaluation.\n# Preparing data for linear regression\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\n\n# Preparing data for linear regression\nX = weather_df[['Humidity']]\ny = weather_df['Temperature']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n\n# Training the model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Making predictions\ny_pred = model.predict(X_test)\n\n# Plotting actual vs predicted values\nplt.scatter(X_test, y_test, color='blue', label='Actual')\nplt.scatter(X_test, y_pred, color='red', label='Predicted')\nplt.xlabel('Humidity')\nplt.ylabel('Temperature')\nplt.title('Actual vs Predicted Temperature')\nplt.legend()\nplt.show()\n\n# Model evaluation\nmse = mean_squared_error(y_test, y_pred)\nprint(\"Mean Squared Error:\", mse)\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-11-output-1.png){width=585 height=449}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nMean Squared Error: 24.010797366937965\n```\n:::\n:::\n\n\n**Markov Chain for Weather Condition Transitions**\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\n#Let's simulate a simple Markov chain to model the transitions between different weather conditions.\nimport pandas as pd\n\n# Calculating transition probabilities\nweather_conditions = weather_df['Weather_Condition'].unique()\ntransition_matrix = pd.DataFrame(index=weather_conditions, columns=weather_conditions).fillna(0)\n\nfor (prev, curr) in zip(weather_df['Weather_Condition'], weather_df['Weather_Condition'][1:]):\n    transition_matrix.at[prev, curr] += 1\n\n# Normalizing the rows to sum to 1\ntransition_matrix = transition_matrix.div(transition_matrix.sum(axis=1), axis=0)\n\n# Display the transition matrix\nprint(transition_matrix)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           Windy     Snowy    Cloudy     Foggy     Sunny     Rainy\nWindy   0.155116  0.165017  0.161716  0.194719  0.181518  0.141914\nSnowy   0.196667  0.166667  0.153333  0.166667  0.156667  0.160000\nCloudy  0.144543  0.182891  0.171091  0.165192  0.188791  0.147493\nFoggy   0.199346  0.124183  0.199346  0.147059  0.140523  0.189542\nSunny   0.167247  0.167247  0.222997  0.167247  0.128920  0.146341\nRainy   0.131488  0.179931  0.211073  0.166090  0.141869  0.169550\n```\n:::\n:::\n\n\nThis code calculates the probabilities of transitioning from one weather condition to another. It's a basic form of a Markov chain.\n\n**Monte Carlo Simulation for Temperature Extremes**\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\n#Use Monte Carlo simulation to estimate the probability of extreme temperature events.\nnp.random.seed(0)\nnum_simulations = 10000\nextreme_temp_count = 0\nextreme_temp_threshold = 30  # Define what you consider as extreme temperature\n\nfor _ in range(num_simulations):\n    simulated_temp = np.random.choice(weather_df['Temperature'])\n    if simulated_temp > extreme_temp_threshold:\n        extreme_temp_count += 1\n\nprobability_of_extreme_temp = extreme_temp_count / num_simulations\nprint(f\"Probability of Extreme Temperature (> {extreme_temp_threshold}°C): {probability_of_extreme_temp}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nProbability of Extreme Temperature (> 30°C): 0.0226\n```\n:::\n:::\n\n\nThis Monte Carlo simulation randomly samples temperatures from the dataset and calculates the probability of encountering temperatures above a certain threshold.\n\n\n# Obtain the logistic function mathematically\n\n## Step 1. Write out the linear regression equation\n$\\Huge y=\\beta_0+\\beta_1 x_1+...+\\beta_n x_n$\n\n\n## Step 2. The logistic regression equation is the same as above except output is log odds\n$\\Huge log(odds)=\\beta_0+\\beta_1 x_1+...+\\beta_n x_n$\n\n\n## Step 3. Exponentiate both sides of the logistic regression equation to get odds\n$\\Huge odds=e^{\\beta_0+\\beta_1 x_1+...+\\beta_n x_n}$\n\n\n## Step 4. Write out the probability equation\n$\\Huge p=\\frac{odds}{1+odds}$\n\n\n## Step 5. Plug odds (from step 3) into the probability equation\n$\\Huge p=\\frac{e^{\\beta_0+\\beta_1 x_1+...+\\beta_n x_n}}{1+e^{\\beta_0+\\beta_1 x_1+...+\\beta_n x_n}}$\n\n\n## Step 6. Divide the numerator and denominator by the odds (from step 3)\n$\\Huge p=\\frac{1}{1+e^{-(\\beta_0+\\beta_1 x_1+...+\\beta_n x_n)}}$\n\n\n$\\Huge P(A\\vert B)={\\frac {P(B\\vert A)P(A)}{P(B)}}$\n\n## Conclusion\n\nThis analysis shows more sophisticated ways of applying probability theory and random processes to the weather dataset, providing insights into weather patterns and temperature predictions.\n\nSummarized the findings from the above analysis. Discussed the relevance of these probabilistic models in understanding weather patterns.\n\n\n\n```{=html}\n<script>\nconst tooltipTriggerList = document.querySelectorAll('[data-bs-toggle=\"tooltip\"]')\nconst tooltipList = [...tooltipTriggerList].map(tooltipTriggerEl => new bootstrap.Tooltip(tooltipTriggerEl))\n</script>\n<style>\ndiv#quarto-sidebar-glass { display: none !important; }\nul.navbar-nav.navbar-nav-scroll { -webkit-flex-direction: row !important; }\n/* #quarto-sidebar { padding: 5px; }\n#quarto-sidebar > * { padding: 5px; }\ndiv.sidebar-menu-container > * { padding: 5px 5px 5px 5px; }\n#quarto-margin-sidebar { padding: 40px; } */\n</style>\n```\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}