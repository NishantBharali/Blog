{
  "hash": "9844f3191e7d681372ffb1c7ba1894e3",
  "result": {
    "markdown": "---\ntitle: Advanced Classification techniques with Model Prediction Analysis\ndescription: \"Implementing advanced classification techniques for precise model prediction analysis to enhance accuracy and efficiency\"\ndate: 11-24-2023\ncategories: [Machine_Learning]\nimage: Rz0T.gif\ntoc-location: right\n---\n\n## Advanced Classification techniques with Model Prediction Analysis\n\n**Implementing advanced classification techniques for precise model prediction analysis to enhance accuracy and efficiency**\n\n## Introduction\n\nMachine learning is a fascinating field that empowers computers to learn and make predictions or decisions without being explicitly programmed. One of the fundamental tasks in machine learning is classification, where the goal is to categorize data points into predefined classes or labels. In this blog post, we dive deep into the world of classification, exploring advanced techniques and their application on a real-world dataset.\n\nThe Iris dataset is a well-known benchmark in the machine learning community. It consists of measurements of four features from three different species of iris flowers. This seemingly simple dataset serves as an excellent playground for understanding and implementing classification algorithms. However, we won't stop at the basics; we'll explore advanced classification techniques, model tuning, and even dive into ensemble methods and neural networks.\n\n**Data Loading and Preliminary Analysis**\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n# Importing essential libraries\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\n# Load dataset\niris_df = pd.read_csv('Iris_dataset.csv')\n\n# Basic dataset information\nprint(iris_df.head())\nprint(iris_df.describe())\nprint(iris_df.info())\n\n# Visualizing the distribution of classes\nsns.countplot(x='species', data=iris_df)\nplt.show()\n\n# Pairplot to explore relationships between features\nsns.pairplot(iris_df, hue='species')\nplt.show()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n0           6.370695          2.771952           5.118790          1.542084   \n1           5.979286          2.612095           5.086595          1.560228   \n2           6.741563          2.804321           4.758669          1.443702   \n3           6.346538          2.796799           5.601084          2.114922   \n4           5.558280          2.831451           4.876331          2.045125   \n\n      species  \n0   virginica  \n1  versicolor  \n2  versicolor  \n3   virginica  \n4   virginica  \n       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\ncount        3000.000000       3000.000000        3000.000000   \nmean            5.844003          3.055776           3.756746   \nstd             0.825203          0.435899           1.761100   \nmin             4.180767          1.918769           0.907839   \n25%             5.118694          2.780525           1.559288   \n50%             5.777010          3.025634           4.347984   \n75%             6.416866          3.342169           5.098831   \nmax             7.963257          4.516746           7.046886   \n\n       petal width (cm)  \ncount       3000.000000  \nmean           1.199022  \nstd            0.760822  \nmin           -0.048888  \n25%            0.310048  \n50%            1.326659  \n75%            1.818514  \nmax            2.601413  \n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3000 entries, 0 to 2999\nData columns (total 5 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   sepal length (cm)  3000 non-null   float64\n 1   sepal width (cm)   3000 non-null   float64\n 2   petal length (cm)  3000 non-null   float64\n 3   petal width (cm)   3000 non-null   float64\n 4   species            3000 non-null   object \ndtypes: float64(4), object(1)\nmemory usage: 117.3+ KB\nNone\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-2-output-2.png){width=601 height=429}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-2-output-3.png){width=1069 height=947}\n:::\n:::\n\n\n**Data Preprocessing**\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\n\n# Encoding categorical data\nencoder = LabelEncoder()\niris_df['species'] = encoder.fit_transform(iris_df['species'])\n\n# Splitting dataset into features and target variable\nX = iris_df.drop('species', axis=1)\ny = iris_df['species']\n\n# Splitting dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Feature scaling\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n```\n:::\n\n\n**Exploratory Data Analysis (EDA)**\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\n# Correlation heatmap\nplt.figure(figsize=(10, 8))\nsns.heatmap(iris_df.corr(), annot=True, cmap='viridis')\nplt.show()\n\n# Advanced pairplot with distribution and regression\nsns.pairplot(iris_df, kind='reg', hue='species')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-4-output-1.png){width=745 height=638}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-4-output-2.png){width=1016 height=947}\n:::\n:::\n\n\n## Model Building and Evaluation For Classification\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\n\n# Function to train and evaluate models\ndef train_evaluate_model(model, X_train, y_train, X_test, y_test):\n    model.fit(X_train, y_train)\n    predictions = model.predict(X_test)\n    print(f'Model: {model.__class__.__name__}')\n    print(classification_report(y_test, predictions))\n    # Confusion matrix\n    cm = confusion_matrix(y_test, predictions)\n    sns.heatmap(cm, annot=True)\n    plt.show()\n\n# Decision Tree Classifier\ntrain_evaluate_model(DecisionTreeClassifier(), X_train, y_train, X_test, y_test)\n\n# RandomForestClassifier\ntrain_evaluate_model(RandomForestClassifier(), X_train, y_train, X_test, y_test)\n\n# GradientBoostingClassifier\ntrain_evaluate_model(GradientBoostingClassifier(), X_train, y_train, X_test, y_test)\n\n# Support Vector Machine (SVC)\ntrain_evaluate_model(SVC(), X_train, y_train, X_test, y_test)\n\n# K-Nearest Neighbors (KNN)\ntrain_evaluate_model(KNeighborsClassifier(), X_train, y_train, X_test, y_test)\n\n# Logistic Regression\ntrain_evaluate_model(LogisticRegression(), X_train, y_train, X_test, y_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel: DecisionTreeClassifier\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00       289\n           1       0.99      0.98      0.98       299\n           2       0.98      0.99      0.99       312\n\n    accuracy                           0.99       900\n   macro avg       0.99      0.99      0.99       900\nweighted avg       0.99      0.99      0.99       900\n\nModel: RandomForestClassifier\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00       289\n           1       0.99      0.99      0.99       299\n           2       0.99      0.99      0.99       312\n\n    accuracy                           1.00       900\n   macro avg       1.00      1.00      1.00       900\nweighted avg       1.00      1.00      1.00       900\n\nModel: GradientBoostingClassifier\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00       289\n           1       0.99      0.99      0.99       299\n           2       0.99      0.99      0.99       312\n\n    accuracy                           1.00       900\n   macro avg       1.00      1.00      1.00       900\nweighted avg       1.00      1.00      1.00       900\n\nModel: SVC\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00       289\n           1       0.99      0.96      0.98       299\n           2       0.97      0.99      0.98       312\n\n    accuracy                           0.98       900\n   macro avg       0.99      0.98      0.98       900\nweighted avg       0.98      0.98      0.98       900\n\nModel: KNeighborsClassifier\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00       289\n           1       1.00      1.00      1.00       299\n           2       1.00      1.00      1.00       312\n\n    accuracy                           1.00       900\n   macro avg       1.00      1.00      1.00       900\nweighted avg       1.00      1.00      1.00       900\n\nModel: LogisticRegression\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00       289\n           1       0.98      0.95      0.97       299\n           2       0.96      0.98      0.97       312\n\n    accuracy                           0.98       900\n   macro avg       0.98      0.98      0.98       900\nweighted avg       0.98      0.98      0.98       900\n\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-5-output-2.png){width=537 height=411}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-5-output-3.png){width=537 height=411}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-5-output-4.png){width=537 height=411}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-5-output-5.png){width=537 height=411}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-5-output-6.png){width=537 height=411}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-5-output-7.png){width=537 height=411}\n:::\n:::\n\n\nIn this code, we introduce different types of classification models, including Random Forest Classifier, Gradient Boosting Classifier, Support Vector Classifier (SVC), K-Nearest Neighbors Classifier (KNN), and Logistic Regression. \n\nFor each model, we train it on the training data and evaluate its performance using accuracy and a classification report that includes precision, recall, and F1-score. This allows you to compare the performance of various classification algorithms on the Iris dataset.\n\n\n**Advanced Model Tuning and Analysis**\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nfrom sklearn.model_selection import GridSearchCV\n\n# Hyperparameter tuning for RandomForestClassifier\nparam_grid = {'n_estimators': [10, 50, 100], 'max_features': ['sqrt', 'log2', None]}\ngrid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)\ngrid_search.fit(X_train, y_train)\nbest_rf = grid_search.best_estimator_\n\n# Evaluating the tuned model\ntrain_evaluate_model(best_rf, X_train, y_train, X_test, y_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel: RandomForestClassifier\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00       289\n           1       0.99      1.00      0.99       299\n           2       1.00      0.99      1.00       312\n\n    accuracy                           1.00       900\n   macro avg       1.00      1.00      1.00       900\nweighted avg       1.00      1.00      1.00       900\n\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-6-output-2.png){width=537 height=411}\n:::\n:::\n\n\n**Hyperparameter Tuning for the Classification Model**\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report, accuracy_score\n\n# Proper Hyperparameter tuning for Random Forest Classifier\nparam_grid_rf = {\n    'n_estimators': [50, 100, 200],\n    'max_depth': [None, 10, 20],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4]\n}\n\ngrid_search_rf = GridSearchCV(RandomForestClassifier(), param_grid_rf, cv=5)\ngrid_search_rf.fit(X_train, y_train)\n\nbest_rf_classifier = grid_search_rf.best_estimator_\n\n# Evaluating the tuned Random Forest Classifier\ntuned_rf_predictions = best_rf_classifier.predict(X_test)\nprint(\"Tuned Random Forest Classifier - Model Evaluation\")\nprint(\"Accuracy:\", accuracy_score(y_test, tuned_rf_predictions))\nprint(\"Classification Report:\")\nprint(classification_report(y_test, tuned_rf_predictions))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTuned Random Forest Classifier - Model Evaluation\nAccuracy: 0.9955555555555555\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00       289\n           1       0.99      0.99      0.99       299\n           2       0.99      0.99      0.99       312\n\n    accuracy                           1.00       900\n   macro avg       1.00      1.00      1.00       900\nweighted avg       1.00      1.00      1.00       900\n\n```\n:::\n:::\n\n\n## ROC Curve Analysis for Multiple Models\n\nComparing the performance of the various classification models using ROC Curve analysis, here we discuss the plots of the ROC Curve for each model. This will involve calculating the True Positive Rate (TPR) and False Positive Rate (FPR) for each model and plotting them.\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.multiclass import OneVsRestClassifier\nimport matplotlib.pyplot as plt\n\n# Binarize the output classes for ROC analysis\ny_bin = label_binarize(y, classes=[0, 1, 2])\nn_classes = y_bin.shape[1]\n\n# Splitting the data again for multiclass ROC analysis\nX_train, X_test, y_train_bin, y_test_bin = train_test_split(X, y_bin, test_size=0.3, random_state=42)\n\n# Classifier list\nclassifiers = [\n    OneVsRestClassifier(DecisionTreeClassifier()),\n    OneVsRestClassifier(RandomForestClassifier()),\n    OneVsRestClassifier(GradientBoostingClassifier()),\n    OneVsRestClassifier(SVC(probability=True)),\n    OneVsRestClassifier(KNeighborsClassifier()),\n    OneVsRestClassifier(LogisticRegression())\n]\n\n# Plotting ROC Curves\nplt.figure(figsize=(10, 8))\n\n# Compute ROC curve and ROC area for each class\nfor classifier in classifiers:\n    classifier.fit(X_train, y_train_bin)\n    y_score = classifier.predict_proba(X_test)\n\n    # Compute ROC curve and ROC area for each class\n    for i in range(n_classes):\n        fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n        roc_auc = auc(fpr, tpr)\n        plt.plot(fpr, tpr, label=f'{classifier.estimator.__class__.__name__} (area = {roc_auc:.2f})')\n\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic for Multi-class')\nplt.legend(loc=\"lower right\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-8-output-1.png){width=823 height=671}\n:::\n:::\n\n\nThis code will generate ROC curves for each of the classifiers used, providing a visual comparison of their performance in terms of the trade-off between the True Positive Rate and False Positive Rate. The area under the curve (AUC) is also displayed as a measure of the model's performance, with a higher AUC indicating a better model. This analysis is crucial for understanding the performance of classification models, especially in multi-class settings.\n\n\n**Dimensionality Reduction and Visualization**\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nfrom sklearn.decomposition import PCA\n\n# PCA for dimensionality reduction\npca = PCA(n_components=2)\nX_train_pca = pca.fit_transform(X_train)\nX_test_pca = pca.transform(X_test)\n\n# Visualizing PCA results\nplt.figure(figsize=(8, 6))\nplt.scatter(X_train_pca[:, 0], X_train_pca[:, 1], c=y_train, cmap='viridis', label='Train set')\nplt.scatter(X_test_pca[:, 0], X_test_pca[:, 1], c=y_test, cmap='plasma', label='Test set', marker='x')\nplt.xlabel('First principal component')\nplt.ylabel('Second principal component')\nplt.legend()\nplt.title('PCA of Iris Dataset')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-9-output-1.png){width=674 height=523}\n:::\n:::\n\n\n## Additional Advanced Analysis\n\n**1. Cross-Validation**\n\nCross-validation is a technique used to evaluate the generalizability of a model by training and testing it on different subsets of the dataset.\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nfrom sklearn.model_selection import cross_val_score\n\n# Example using RandomForestClassifier\nrf_classifier = RandomForestClassifier()\n\n# Performing 10-fold cross-validation\ncv_scores = cross_val_score(rf_classifier, X, y, cv=10)\n\nprint(\"Cross-Validation Scores for RandomForestClassifier:\", cv_scores)\nprint(\"Average Score:\", np.mean(cv_scores))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCross-Validation Scores for RandomForestClassifier: [1.         1.         0.99333333 0.99333333 1.         0.99666667\n 0.99666667 0.99333333 1.         1.        ]\nAverage Score: 0.9973333333333333\n```\n:::\n:::\n\n\n**2. Ensemble Methods**\n\nEnsemble methods combine multiple models to improve the overall performance. Here, I will use an ensemble of different classifiers.\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import VotingClassifier\n\n# Update Logistic Regression in the ensemble\nclassifiers = [\n    ('Decision Tree', DecisionTreeClassifier()),\n    ('Random Forest', RandomForestClassifier()),\n    ('Gradient Boosting', GradientBoostingClassifier()),\n    ('SVC', SVC(probability=True)),\n    ('KNN', KNeighborsClassifier()),\n    ('Logistic Regression', LogisticRegression(max_iter=1000))\n]\n\nensemble = VotingClassifier(estimators=classifiers, voting='soft')\nensemble.fit(X_train, y_train)\nensemble_predictions = ensemble.predict(X_test)\n\nprint(\"Ensemble Model Classification Report:\")\nprint(classification_report(y_test, ensemble_predictions))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEnsemble Model Classification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00       289\n           1       1.00      0.99      0.99       299\n           2       0.99      1.00      1.00       312\n\n    accuracy                           1.00       900\n   macro avg       1.00      1.00      1.00       900\nweighted avg       1.00      1.00      1.00       900\n\n```\n:::\n:::\n\n\n## PREDICTION\n\n**Prediction: Data Preprocessing with Visualization**\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Encoding categorical data\nencoder = LabelEncoder()\niris_df['species'] = encoder.fit_transform(iris_df['species'])\n\n# Visualizing the distribution of the target variable\nplt.figure(figsize=(8, 5))\nsns.countplot(x='species', data=iris_df)\nplt.title('Distribution of Target Variable (Species)')\nplt.show()\n\n# Splitting dataset into features and target variable\nX = iris_df.drop('species', axis=1)\ny = iris_df['species']\n\n# Splitting dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Feature scaling\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Pairplot to explore relationships between features\npairplot_df = iris_df.copy()\npairplot_df['species'] = encoder.inverse_transform(pairplot_df['species'])\n\nplt.figure(figsize=(10, 8))\nsns.pairplot(pairplot_df, hue='species')\nplt.title('Pairplot of Features with Species as Hue')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-12-output-1.png){width=676 height=449}\n:::\n\n::: {.cell-output .cell-output-display}\n```\n<Figure size 960x768 with 0 Axes>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-12-output-3.png){width=1016 height=947}\n:::\n:::\n\n\n## Model Building, Evaluation, and Visualization for Prediction\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nimport matplotlib.pyplot as plt\n\n# Function to train and evaluate regression models\ndef train_evaluate_regression_model(model, X_train, y_train, X_test, y_test):\n    model.fit(X_train, y_train)\n    predictions = model.predict(X_test)\n    \n    # Model Evaluation\n    print(f'Model: {model.__class__.__name__}')\n    print(f'Mean Squared Error: {mean_squared_error(y_test, predictions)}')\n    print(f'R-squared (R2) Score: {r2_score(y_test, predictions)}')\n    \n    # Visualization\n    plt.figure(figsize=(8, 5))\n    plt.scatter(y_test, predictions)\n    plt.xlabel('True Values')\n    plt.ylabel('Predictions')\n    plt.title(f'{model.__class__.__name__} - True vs. Predicted Values')\n    plt.show()\n\n# Linear Regression\ntrain_evaluate_regression_model(LinearRegression(), X_train, y_train, X_test, y_test)\n\n# Decision Tree Regressor\ntrain_evaluate_regression_model(DecisionTreeRegressor(), X_train, y_train, X_test, y_test)\n\n# Random Forest Regressor\ntrain_evaluate_regression_model(RandomForestRegressor(), X_train, y_train, X_test, y_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel: LinearRegression\nMean Squared Error: 0.047703003079178956\nR-squared (R2) Score: 0.9284946222241109\nModel: DecisionTreeRegressor\nMean Squared Error: 0.0077777777777777776\nR-squared (R2) Score: 0.9883413432623143\nModel: RandomForestRegressor\nMean Squared Error: 0.006260222222222222\nR-squared (R2) Score: 0.9906161137440759\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-13-output-2.png){width=663 height=449}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-13-output-3.png){width=672 height=449}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-13-output-4.png){width=672 height=449}\n:::\n:::\n\n\n**Advanced Model Tuning and Analysis for Prediction**\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\nfrom sklearn.model_selection import GridSearchCV\n\n# Hyperparameter tuning for Random Forest Regressor\nparam_grid = {\n    'n_estimators': [10, 50, 100],\n    'max_depth': [None, 10, 20, 30],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4]\n}\n\ngrid_search = GridSearchCV(RandomForestRegressor(), param_grid, cv=5, scoring='neg_mean_squared_error')\ngrid_search.fit(X_train, y_train)\n\nbest_rf = grid_search.best_estimator_\n\n# Evaluating the tuned model\npredictions = best_rf.predict(X_test)\nprint(\"Tuned Random Forest Regressor - Model Evaluation\")\nprint(f'Mean Squared Error: {mean_squared_error(y_test, predictions)}')\nprint(f'R-squared (R2) Score: {r2_score(y_test, predictions)}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTuned Random Forest Regressor - Model Evaluation\nMean Squared Error: 0.006044444444444445\nR-squared (R2) Score: 0.9909395581924271\n```\n:::\n:::\n\n\n**Feature Selection and Importance Analysis**\n\nFeature selection is crucial for improving model performance and reducing overfitting. Here, we use techniques like Recursive Feature Elimination (RFE) and feature importance analysis to select the most relevant features for classification or prediction.\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LogisticRegression\n\n# Using Recursive Feature Elimination (RFE) with Logistic Regression\nmodel = LogisticRegression()\nrfe = RFE(model, n_features_to_select=3)  # Select the top 3 features\nfit = rfe.fit(X_train, y_train)\n\n# List of selected features\nselected_features = [feature for idx, feature in enumerate(X.columns) if fit.support_[idx]]\nprint(\"Selected Features:\", selected_features)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSelected Features: ['sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n```\n:::\n:::\n\n\nAdditionally, we can analyze feature importance for tree-based models like Random Forest or Gradient Boosting to understand which features contribute the most to predictions.\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Feature Importance Analysis for Random Forest Classifier\nrf_model = RandomForestClassifier()\nrf_model.fit(X_train, y_train)\n\n# Plot feature importance\nfeature_importance = pd.Series(rf_model.feature_importances_, index=X.columns)\nfeature_importance.nlargest(5).plot(kind='barh')\nplt.title(\"Feature Importance (Random Forest)\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-16-output-1.png){width=666 height=431}\n:::\n:::\n\n\n**Handling Class Imbalance**\n\nIn real-world datasets, class imbalance is common, where one class has significantly fewer samples than others. Techniques like oversampling, undersampling, and Synthetic Minority Over-sampling Technique (SMOTE) can be employed to address this issue.\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\nfrom imblearn.over_sampling import SMOTE\n\n# Using SMOTE to handle class imbalance\nsmote = SMOTE(sampling_strategy='auto')\nX_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n```\n:::\n\n\n## Conclusion\n\nIn this journey through the Iris dataset and the realm of classification, we've covered a wide range of topics. Starting with data loading and preprocessing, we explored the relationships between features, ensuring that we understood our data thoroughly. We then introduced a variety of classification models, from decision trees to support vector machines, and compared their performance using robust evaluation metrics.\n\nBut we didn't stop there. We delved into advanced techniques, including cross-validation to ensure the generalizability of our models, ensemble methods that combined the strengths of multiple classifiers, and even a taste of neural networks for classification tasks.\n\nOur exploration of ROC curves allowed us to visualize and compare the trade-offs between true positive and false positive rates across different models, providing valuable insights into their performance.\n\nIn the end, classification is a powerful tool in the machine learning toolkit, with applications ranging from medical diagnosis to spam email filtering. The Iris dataset served as an ideal playground to learn and experiment with these techniques, but the knowledge gained can be applied to more complex and real-world classification problems.\n\nAs you continue your journey in machine learning, remember that classification is just the tip of the iceberg. The world of machine learning is vast and ever-evolving, and there are countless exciting challenges and opportunities awaiting those who dare to explore it further.\n\n\n```{=html}\n<script>\nconst tooltipTriggerList = document.querySelectorAll('[data-bs-toggle=\"tooltip\"]')\nconst tooltipList = [...tooltipTriggerList].map(tooltipTriggerEl => new bootstrap.Tooltip(tooltipTriggerEl))\n</script>\n<style>\ndiv#quarto-sidebar-glass { display: none !important; }\nul.navbar-nav.navbar-nav-scroll { -webkit-flex-direction: row !important; }\n/* #quarto-sidebar { padding: 5px; }\n#quarto-sidebar > * { padding: 5px; }\ndiv.sidebar-menu-container > * { padding: 5px 5px 5px 5px; }\n#quarto-margin-sidebar { padding: 40px; } */\n</style>\n```\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}